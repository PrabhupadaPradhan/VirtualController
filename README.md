# VirtualController

# Gesture-Controlled Virtual Mouse and Keyboard

This project leverages computer vision to create a **Virtual Mouse** and **Virtual Keyboard** controlled entirely by hand gestures, providing an innovative touchless interaction experience. Using Python and libraries like PyAutoGUI, Mediapipe, OpenCV, and NumPy, the system detects and interprets real-time hand gestures via a webcam.

## Features

- **Virtual Mouse**
  - Control cursor movement using hand gestures.
  - Perform left-click, right-click, and drag actions seamlessly.
  
- **Virtual Keyboard**
  - Enable text input through gesture recognition.
  - Display an on-screen keyboard for real-time interaction.

- **Real-Time Hand Tracking**
  - Powered by Mediapipe's robust hand tracking model.
  - High accuracy and responsiveness for dynamic gestures.

## Technologies Used

- **Python**
- **PyAutoGUI**: Automate mouse and keyboard actions.
- **Mediapipe**: Hand tracking and gesture recognition.
- **OpenCV**: Image processing and webcam integration.
- **NumPy**: Efficient data handling and computation.
